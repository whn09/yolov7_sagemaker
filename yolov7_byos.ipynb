{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch BYOS\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note, you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.96.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-yolov7'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    ## Set type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cfg': 'file:///home/ec2-user/SageMaker/yolov7_sagemaker/data/cfg/', 'weights': 'file:///home/ec2-user/SageMaker/yolov7_sagemaker/data/weights/', 'images': 'file:///home/ec2-user/SageMaker/yolov7_sagemaker/data/images/', 'labels': 'file:///home/ec2-user/SageMaker/yolov7_sagemaker/data/labels/'}\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'file:///home/ec2-user/SageMaker/yolov7_sagemaker/data/'\n",
    "inputs = {'cfg': base_dir+'cfg/', 'weights': base_dir+'weights/', 'images': base_dir+'images/', 'labels': base_dir+'labels/'}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating nc0hdyraoc-algo-1-qdwti ... \n",
      "Creating nc0hdyraoc-algo-1-qdwti ... done\n",
      "Attaching to nc0hdyraoc-algo-1-qdwti\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:36,839 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:36,840 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:36,848 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:36,851 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:37,901 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m /opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.5.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.21.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (4.5.4.60)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (8.3.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (5.4.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (2.26.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.9.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.10.1+cpu)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: protobuf<4.21.3 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (3.19.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting tensorboard>=2.4.1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 21)) (1.3.4)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 34)) (7.18.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 35)) (5.6.7)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting thop\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (6.3.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (21.3)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.28.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.7)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.4)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.0.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.37.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting google-auth<3,>=1.6.3\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting absl-py>=0.4\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting markdown>=2.6.8\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.0.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting grpcio>=1.24.3\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (59.4.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting tensorboard-plugin-wit>=1.6.0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2021.3)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (3.0.8)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (5.0.5)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (0.18.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython->-r requirements.txt (line 34)) (2.7.1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.7.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting cachetools<6.0,>=2.0.0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting requests-oauthlib>=0.7.0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.8.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.6.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.5)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.2)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.2->ipython->-r requirements.txt (line 34)) (0.2.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.6.0)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Collecting oauthlib>=3.0.0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, thop, tensorboard\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Successfully installed absl-py-1.2.0 cachetools-5.2.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 grpcio-1.47.0 markdown-3.4.1 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 thop-0.1.1.post2207130030\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:42,356 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:42,367 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:42,376 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2022-08-02 10:12:42,385 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Training Env:\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"cfg\": \"/opt/ml/input/data/cfg\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"weights\": \"/opt/ml/input/data/weights\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"images\": \"/opt/ml/input/data/images\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"labels\": \"/opt/ml/input/data/labels\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"current_host\": \"algo-1-qdwti\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"algo-1-qdwti\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     ],\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"data\": \"/opt/ml/input/data/cfg/coco128.yaml\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"weight\": \"/opt/ml/input/data/weights/yolov7.pt\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"project\": \"/opt/ml/model/\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"name\": \"tutorial\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"img\": 640,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"batch\": 2,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"epochs\": 5,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"workers\": 1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"cfg\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"weights\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"images\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"labels\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         }\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"job_name\": \"pytorch-training-2022-08-02-10-12-27-134\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"master_hostname\": \"algo-1-qdwti\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-579019700964/pytorch-training-2022-08-02-10-12-27-134/source/sourcedir.tar.gz\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"current_host\": \"algo-1-qdwti\",\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m             \"algo-1-qdwti\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m         ]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     },\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m }\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Environment variables:\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HOSTS=[\"algo-1-qdwti\"]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HPS={\"batch\":2,\"data\":\"/opt/ml/input/data/cfg/coco128.yaml\",\"epochs\":5,\"img\":640,\"name\":\"tutorial\",\"project\":\"/opt/ml/model/\",\"weight\":\"/opt/ml/input/data/weights/yolov7.pt\",\"workers\":1}\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-qdwti\",\"hosts\":[\"algo-1-qdwti\"]}\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_INPUT_DATA_CONFIG={\"cfg\":{\"TrainingInputMode\":\"File\"},\"images\":{\"TrainingInputMode\":\"File\"},\"labels\":{\"TrainingInputMode\":\"File\"},\"weights\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CHANNELS=[\"cfg\",\"images\",\"labels\",\"weights\"]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CURRENT_HOST=algo-1-qdwti\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-579019700964/pytorch-training-2022-08-02-10-12-27-134/source/sourcedir.tar.gz\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"cfg\":\"/opt/ml/input/data/cfg\",\"images\":\"/opt/ml/input/data/images\",\"labels\":\"/opt/ml/input/data/labels\",\"weights\":\"/opt/ml/input/data/weights\"},\"current_host\":\"algo-1-qdwti\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-qdwti\"],\"hyperparameters\":{\"batch\":2,\"data\":\"/opt/ml/input/data/cfg/coco128.yaml\",\"epochs\":5,\"img\":640,\"name\":\"tutorial\",\"project\":\"/opt/ml/model/\",\"weight\":\"/opt/ml/input/data/weights/yolov7.pt\",\"workers\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"cfg\":{\"TrainingInputMode\":\"File\"},\"images\":{\"TrainingInputMode\":\"File\"},\"labels\":{\"TrainingInputMode\":\"File\"},\"weights\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-08-02-10-12-27-134\",\"log_level\":20,\"master_hostname\":\"algo-1-qdwti\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-579019700964/pytorch-training-2022-08-02-10-12-27-134/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-qdwti\",\"hosts\":[\"algo-1-qdwti\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_USER_ARGS=[\"--batch\",\"2\",\"--data\",\"/opt/ml/input/data/cfg/coco128.yaml\",\"--epochs\",\"5\",\"--img\",\"640\",\"--name\",\"tutorial\",\"--project\",\"/opt/ml/model/\",\"--weight\",\"/opt/ml/input/data/weights/yolov7.pt\",\"--workers\",\"1\"]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CHANNEL_CFG=/opt/ml/input/data/cfg\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CHANNEL_WEIGHTS=/opt/ml/input/data/weights\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CHANNEL_IMAGES=/opt/ml/input/data/images\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_CHANNEL_LABELS=/opt/ml/input/data/labels\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_DATA=/opt/ml/input/data/cfg/coco128.yaml\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_WEIGHT=/opt/ml/input/data/weights/yolov7.pt\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_PROJECT=/opt/ml/model/\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_NAME=tutorial\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_IMG=640\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_BATCH=2\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_EPOCHS=5\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m SM_HP_WORKERS=1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m /opt/conda/bin/python3.8 train.py --batch 2 --data /opt/ml/input/data/cfg/coco128.yaml --epochs 5 --img 640 --name tutorial --project /opt/ml/model/ --weight /opt/ml/input/data/weights/yolov7.pt --workers 1\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m YOLOR ðŸš€ v0.1-82-gc51c13a torch 1.9.1 CPU\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/opt/ml/input/data/cfg/coco128.yaml', device='', entity=None, epochs=5, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='tutorial', noautoanchor=False, nosave=False, notest=False, project='/opt/ml/model/', quad=False, rect=False, resume=False, save_dir='/opt/ml/model/tutorial', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, weights='/opt/ml/input/data/weights/yolov7.pt', workers=1, world_size=1)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir /opt/ml/model/', view at http://localhost:6006/\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m from  n    params  module                                  arguments\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 12                -1  1         0  models.common.MP                        []\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 16          [-1, -3]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 25                -1  1         0  models.common.MP                        []\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 29          [-1, -3]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 38                -1  1         0  models.common.MP                        []\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 42          [-1, -3]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 55          [-1, -2]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 67          [-1, -2]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 76                -1  1         0  models.common.MP                        []\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 89                -1  1         0  models.common.MP                        []\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 105   [102, 103, 104]  1    457725  models.yolo.Detect                      [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m [2022-08-02 10:12:45.503 algo-1-qdwti:43 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m [2022-08-02 10:12:45.550 algo-1-qdwti:43 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Model Summary: 407 layers, 37620125 parameters, 37620125 gradients, 106.5 GFLOPS\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Transferred 560/560 items from /opt/ml/input/data/weights/yolov7.pt\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Scaled weight_decay = 0.0005\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Optimizer groups: 95 .bias, 95 conv.weight, 92 other\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Scanning images:   0%|          | 0/128 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mScanning '/opt/ml/input/data/labels/train' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 2968.30it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /opt/ml/input/data/labels/train.cache\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mScanning '/opt/ml/input/data/labels/train.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mScanning '/opt/ml/input/data/labels/train.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors...\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m anchors/target = 4.22, Best Possible Recall (BPR) = 0.9882\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m \n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Image sizes 640 train, 640 test\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Using 1 dataloader workers\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Logging results to /opt/ml/model/tutorial\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Starting training for 5 epochs...\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0%|          | 0/64 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02094   0.02006  0.001257   0.04225        18       640:   0%|          | 0/64 [00:03<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02094   0.02006  0.001257   0.04225        18       640:   2%|â–         | 1/64 [00:03<03:58,  3.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02664   0.01975  0.009867   0.05626        12       640:   2%|â–         | 1/64 [00:06<03:58,  3.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02664   0.01975  0.009867   0.05626        12       640:   3%|â–Ž         | 2/64 [00:06<03:31,  3.41s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02565   0.01877  0.007504   0.05193        28       640:   3%|â–Ž         | 2/64 [00:09<03:31,  3.41s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02565   0.01877  0.007504   0.05193        28       640:   5%|â–         | 3/64 [00:09<03:13,  3.17s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02572   0.01982  0.006302   0.05184        27       640:   5%|â–         | 3/64 [00:12<03:13,  3.17s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02572   0.01982  0.006302   0.05184        27       640:   6%|â–‹         | 4/64 [00:12<03:02,  3.04s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02735   0.02462  0.006535   0.05851       104       640:   6%|â–‹         | 4/64 [00:15<03:02,  3.04s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02735   0.02462  0.006535   0.05851       104       640:   8%|â–Š         | 5/64 [00:15<02:56,  3.00s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02599   0.02325  0.006875   0.05611        12       640:   8%|â–Š         | 5/64 [00:18<02:56,  3.00s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02599   0.02325  0.006875   0.05611        12       640:   9%|â–‰         | 6/64 [00:18<02:52,  2.97s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0269   0.02415  0.007683   0.05874        28       640:   9%|â–‰         | 6/64 [00:21<02:52,  2.97s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0269   0.02415  0.007683   0.05874        28       640:  11%|â–ˆ         | 7/64 [00:21<02:47,  2.95s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02706   0.02417  0.008014   0.05925        18       640:  11%|â–ˆ         | 7/64 [00:24<02:47,  2.95s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02706   0.02417  0.008014   0.05925        18       640:  12%|â–ˆâ–Ž        | 8/64 [00:24<02:43,  2.93s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02759    0.0272  0.007665   0.06245       101       640:  12%|â–ˆâ–Ž        | 8/64 [00:27<02:43,  2.93s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02759    0.0272  0.007665   0.06245       101       640:  14%|â–ˆâ–        | 9/64 [00:27<02:41,  2.93s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02868   0.02698  0.009736   0.06539        14       640:  14%|â–ˆâ–        | 9/64 [00:29<02:41,  2.93s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02868   0.02698  0.009736   0.06539        14       640:  16%|â–ˆâ–Œ        | 10/64 [00:29<02:35,  2.88s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02865   0.02584  0.009003   0.06349        11       640:  16%|â–ˆâ–Œ        | 10/64 [00:32<02:35,  2.88s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02865   0.02584  0.009003   0.06349        11       640:  17%|â–ˆâ–‹        | 11/64 [00:32<02:32,  2.88s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02801   0.02693  0.009359    0.0643        32       640:  17%|â–ˆâ–‹        | 11/64 [00:35<02:32,  2.88s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02801   0.02693  0.009359    0.0643        32       640:  19%|â–ˆâ–‰        | 12/64 [00:35<02:28,  2.86s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02739   0.02631   0.00932   0.06302        14       640:  19%|â–ˆâ–‰        | 12/64 [00:38<02:28,  2.86s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02739   0.02631   0.00932   0.06302        14       640:  20%|â–ˆâ–ˆ        | 13/64 [00:38<02:24,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02783   0.02702   0.01009   0.06493        19       640:  20%|â–ˆâ–ˆ        | 13/64 [00:41<02:24,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02783   0.02702   0.01009   0.06493        19       640:  22%|â–ˆâ–ˆâ–       | 14/64 [00:41<02:20,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02762   0.02893  0.009636   0.06619        47       640:  22%|â–ˆâ–ˆâ–       | 14/64 [00:44<02:20,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02762   0.02893  0.009636   0.06619        47       640:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:44<02:17,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02744   0.02879  0.009335   0.06556        24       640:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:46<02:17,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02744   0.02879  0.009335   0.06556        24       640:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:46<02:16,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02708   0.02936  0.009053   0.06549        48       640:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:49<02:16,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02708   0.02936  0.009053   0.06549        48       640:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:49<02:12,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02782   0.02882  0.009224   0.06586        23       640:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:52<02:12,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02782   0.02882  0.009224   0.06586        23       640:  28%|â–ˆâ–ˆâ–Š       | 18/64 [00:52<02:09,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0283   0.02906  0.009661   0.06702        63       640:  28%|â–ˆâ–ˆâ–Š       | 18/64 [00:55<02:09,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0283   0.02906  0.009661   0.06702        63       640:  30%|â–ˆâ–ˆâ–‰       | 19/64 [00:55<02:06,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02778   0.02797   0.00981   0.06556         8       640:  30%|â–ˆâ–ˆâ–‰       | 19/64 [00:58<02:06,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02778   0.02797   0.00981   0.06556         8       640:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:58<02:04,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02779   0.02753  0.009527   0.06485        30       640:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [01:00<02:04,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02779   0.02753  0.009527   0.06485        30       640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/64 [01:00<02:00,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02807   0.02813  0.009738   0.06594        76       640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/64 [01:03<02:00,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02807   0.02813  0.009738   0.06594        76       640:  34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [01:03<01:56,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02777   0.02861  0.009843   0.06622        38       640:  34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [01:06<01:56,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02777   0.02861  0.009843   0.06622        38       640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [01:06<01:53,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02757   0.02861   0.01035   0.06653        20       640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [01:09<01:53,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02757   0.02861   0.01035   0.06653        20       640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [01:09<01:51,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02733   0.02837   0.01015   0.06586        29       640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [01:12<01:51,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02733   0.02837   0.01015   0.06586        29       640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [01:12<01:50,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02737   0.02915  0.009851   0.06636        50       640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [01:14<01:50,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02737   0.02915  0.009851   0.06636        50       640:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [01:14<01:45,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02751   0.02949  0.009771   0.06677        33       640:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [01:17<01:45,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02751   0.02949  0.009771   0.06677        33       640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [01:17<01:45,  2.85s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.02941  0.009636   0.06653        26       640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [01:20<01:45,  2.85s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.02941  0.009636   0.06653        26       640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [01:20<01:40,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02741   0.02938  0.009653   0.06644        40       640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [01:23<01:40,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02741   0.02938  0.009653   0.06644        40       640:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [01:23<01:37,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02701   0.02919  0.009679   0.06587        14       640:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [01:26<01:37,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02701   0.02919  0.009679   0.06587        14       640:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [01:26<01:34,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02718   0.02943   0.01007   0.06667        28       640:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [01:28<01:34,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02718   0.02943   0.01007   0.06667        28       640:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [01:28<01:31,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02693   0.02903  0.009979   0.06594        13       640:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [01:31<01:31,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02693   0.02903  0.009979   0.06594        13       640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [01:31<01:27,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02692   0.02879  0.009788    0.0655        15       640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [01:34<01:27,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02692   0.02879  0.009788    0.0655        15       640:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [01:34<01:27,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02679   0.02862  0.009807   0.06521        30       640:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [01:37<01:27,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02679   0.02862  0.009807   0.06521        30       640:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [01:37<01:23,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02668   0.02851  0.009562   0.06475        40       640:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [01:39<01:23,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02668   0.02851  0.009562   0.06475        40       640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [01:39<01:20,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02697    0.0288  0.009813   0.06558        18       640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [01:42<01:20,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02697    0.0288  0.009813   0.06558        18       640:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [01:42<01:16,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.02861  0.009879   0.06598        24       640:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [01:45<01:16,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.02861  0.009879   0.06598        24       640:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [01:45<01:15,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02744   0.02861  0.009845    0.0659        29       640:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [01:48<01:15,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02744   0.02861  0.009845    0.0659        29       640:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [01:48<01:11,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02758   0.02987  0.009829   0.06728       121       640:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [01:51<01:11,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02758   0.02987  0.009829   0.06728       121       640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [01:51<01:09,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02755   0.03127  0.009749   0.06857        90       640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [01:53<01:09,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02755   0.03127  0.009749   0.06857        90       640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/64 [01:53<01:07,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02761   0.03121  0.009727   0.06855        34       640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/64 [01:56<01:07,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02761   0.03121  0.009727   0.06855        34       640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [01:56<01:04,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02808   0.03107   0.01019   0.06934        43       640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [01:59<01:04,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02808   0.03107   0.01019   0.06934        43       640:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [01:59<01:01,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02803   0.03061    0.0104   0.06905         6       640:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [02:02<01:01,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02803   0.03061    0.0104   0.06905         6       640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [02:02<00:58,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02808   0.03076   0.01033   0.06916        69       640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [02:04<00:58,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02808   0.03076   0.01033   0.06916        69       640:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [02:04<00:54,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0282   0.03049   0.01031   0.06901        30       640:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [02:07<00:54,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G    0.0282   0.03049   0.01031   0.06901        30       640:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [02:07<00:52,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02791   0.03008   0.01036   0.06835         7       640:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [02:10<00:52,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02791   0.03008   0.01036   0.06835         7       640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [02:10<00:49,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02768   0.02983   0.01032   0.06782        16       640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [02:12<00:49,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02768   0.02983   0.01032   0.06782        16       640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 47/64 [02:12<00:46,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02759   0.02985   0.01026    0.0677        32       640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 47/64 [02:15<00:46,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02759   0.02985   0.01026    0.0677        32       640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/64 [02:15<00:44,  2.77s/it]\n",
      "       0/4        0G   0.02775   0.02978   0.01033   0.06787        18       640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [02:18<00:41,  2.79s/it]/64 [02:18<00:44,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02765   0.02978   0.01032   0.06775        32       640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [02:21<00:41,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02765   0.02978   0.01032   0.06775        32       640:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [02:21<00:38,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02782   0.03003   0.01041   0.06827        30       640:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [02:24<00:38,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02782   0.03003   0.01041   0.06827        30       640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [02:24<00:35,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02766   0.02997   0.01034   0.06797        36       640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [02:26<00:35,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02766   0.02997   0.01034   0.06797        36       640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [02:26<00:33,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02758   0.02987   0.01025   0.06771        25       640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [02:30<00:33,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02758   0.02987   0.01025   0.06771        25       640:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 53/64 [02:30<00:33,  3.04s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02743   0.02992   0.01025    0.0676        26       640:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 53/64 [02:33<00:33,  3.04s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02743   0.02992   0.01025    0.0676        26       640:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [02:33<00:29,  3.00s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02753   0.02987   0.01025   0.06765        15       640:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [02:36<00:29,  3.00s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02753   0.02987   0.01025   0.06765        15       640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [02:36<00:26,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02753   0.03015    0.0102   0.06788        56       640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [02:39<00:26,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02753   0.03015    0.0102   0.06788        56       640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [02:39<00:23,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02751   0.03009   0.01016   0.06776        55       640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [02:41<00:23,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02751   0.03009   0.01016   0.06776        55       640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [02:41<00:19,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02747   0.03022   0.01018   0.06787        33       640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [02:44<00:19,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02747   0.03022   0.01018   0.06787        33       640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [02:44<00:16,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.03056   0.01034   0.06839        58       640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [02:47<00:16,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02749   0.03056   0.01034   0.06839        58       640:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [02:47<00:13,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02757    0.0309   0.01046   0.06892        50       640:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [02:49<00:13,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02757    0.0309   0.01046   0.06892        50       640:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [02:49<00:11,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02756   0.03079   0.01073   0.06908        10       640:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [02:52<00:11,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02756   0.03079   0.01073   0.06908        10       640:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [02:52<00:08,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02773   0.03054   0.01079   0.06906        21       640:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [02:55<00:08,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02773   0.03054   0.01079   0.06906        21       640:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [02:55<00:05,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02774   0.03033    0.0108   0.06887        12       640:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [02:58<00:05,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02774   0.03033    0.0108   0.06887        12       640:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [02:58<00:02,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02769   0.03011   0.01081   0.06861        15       640:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [03:00<00:02,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02769   0.03011   0.01081   0.06861        15       640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [03:00<00:00,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0/4        0G   0.02769   0.03011   0.01081   0.06861        15       640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [03:00<00:00,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/32 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   3%|â–Ž         | 1/32 [00:01<00:39,  1.27s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   6%|â–‹         | 2/32 [00:02<00:45,  1.52s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   9%|â–‰         | 3/32 [00:04<00:46,  1.59s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  12%|â–ˆâ–Ž        | 4/32 [00:06<00:45,  1.62s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  16%|â–ˆâ–Œ        | 5/32 [00:07<00:44,  1.63s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  19%|â–ˆâ–‰        | 6/32 [00:09<00:42,  1.64s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  22%|â–ˆâ–ˆâ–       | 7/32 [00:11<00:41,  1.65s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:12<00:39,  1.65s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  28%|â–ˆâ–ˆâ–Š       | 9/32 [00:14<00:38,  1.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:16<00:38,  1.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:18<00:37,  1.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:20<00:36,  1.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:22<00:35,  1.85s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:24<00:33,  1.87s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:26<00:31,  1.87s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:27<00:30,  1.88s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:29<00:28,  1.89s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [00:31<00:26,  1.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [00:33<00:24,  1.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:35<00:22,  1.91s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:37<00:20,  1.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:39<00:19,  1.98s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [00:42<00:19,  2.21s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [00:45<00:18,  2.33s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:47<00:16,  2.32s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [00:49<00:13,  2.24s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:51<00:10,  2.16s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [00:53<00:08,  2.09s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:55<00:06,  2.05s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:56<00:03,  1.95s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [00:58<00:01,  1.87s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:00<00:00,  1.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:00<00:00,  1.89s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m all         128         929       0.787       0.797       0.842       0.635\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 0%|          | 0/64 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02797    0.0185   0.02328   0.06974        14       640:   0%|          | 0/64 [00:03<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02797    0.0185   0.02328   0.06974        14       640:   2%|â–         | 1/64 [00:03<03:21,  3.20s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02772   0.02986    0.0189   0.07648        33       640:   2%|â–         | 1/64 [00:06<03:21,  3.20s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02772   0.02986    0.0189   0.07648        33       640:   3%|â–Ž         | 2/64 [00:06<03:11,  3.09s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02817    0.0247   0.01623    0.0691        28       640:   3%|â–Ž         | 2/64 [00:09<03:11,  3.09s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02817    0.0247   0.01623    0.0691        28       640:   5%|â–         | 3/64 [00:09<03:03,  3.01s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02957   0.03028   0.01498   0.07483        45       640:   5%|â–         | 3/64 [00:11<03:03,  3.01s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02957   0.03028   0.01498   0.07483        45       640:   6%|â–‹         | 4/64 [00:11<02:53,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03057   0.03285   0.01668   0.08011        42       640:   6%|â–‹         | 4/64 [00:14<02:53,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03057   0.03285   0.01668   0.08011        42       640:   8%|â–Š         | 5/64 [00:14<02:48,  2.85s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02908   0.03066   0.02096   0.08069         7       640:   8%|â–Š         | 5/64 [00:17<02:48,  2.85s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02908   0.03066   0.02096   0.08069         7       640:   9%|â–‰         | 6/64 [00:17<02:42,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02848   0.03018   0.01878   0.07744        34       640:   9%|â–‰         | 6/64 [00:20<02:42,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02848   0.03018   0.01878   0.07744        34       640:  11%|â–ˆ         | 7/64 [00:20<02:39,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02865   0.03375   0.02004   0.08244        41       640:  11%|â–ˆ         | 7/64 [00:22<02:39,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02865   0.03375   0.02004   0.08244        41       640:  12%|â–ˆâ–Ž        | 8/64 [00:22<02:33,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0299     0.032   0.02066   0.08255         9       640:  12%|â–ˆâ–Ž        | 8/64 [00:25<02:33,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0299     0.032   0.02066   0.08255         9       640:  14%|â–ˆâ–        | 9/64 [00:25<02:29,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0303   0.03073   0.02012   0.08114        34       640:  14%|â–ˆâ–        | 9/64 [00:28<02:29,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0303   0.03073   0.02012   0.08114        34       640:  16%|â–ˆâ–Œ        | 10/64 [00:28<02:27,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02985   0.03369   0.01868   0.08223        93       640:  16%|â–ˆâ–Œ        | 10/64 [00:30<02:27,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.02985   0.03369   0.01868   0.08223        93       640:  17%|â–ˆâ–‹        | 11/64 [00:30<02:24,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03434    0.0323   0.01928   0.08592        51       640:  17%|â–ˆâ–‹        | 11/64 [00:33<02:24,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03434    0.0323   0.01928   0.08592        51       640:  19%|â–ˆâ–‰        | 12/64 [00:33<02:20,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03379   0.03259   0.01869   0.08507        63       640:  19%|â–ˆâ–‰        | 12/64 [00:36<02:20,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03379   0.03259   0.01869   0.08507        63       640:  20%|â–ˆâ–ˆ        | 13/64 [00:36<02:16,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03397   0.03192   0.01811     0.084        41       640:  20%|â–ˆâ–ˆ        | 13/64 [00:38<02:16,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03397   0.03192   0.01811     0.084        41       640:  22%|â–ˆâ–ˆâ–       | 14/64 [00:38<02:13,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03374   0.03141   0.01827   0.08342        20       640:  22%|â–ˆâ–ˆâ–       | 14/64 [00:41<02:13,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03374   0.03141   0.01827   0.08342        20       640:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:41<02:11,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03362   0.03067   0.01824   0.08254        60       640:  23%|â–ˆâ–ˆâ–Ž       | 15/64 [00:44<02:11,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03362   0.03067   0.01824   0.08254        60       640:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:44<02:08,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03463   0.03048   0.01822   0.08333        41       640:  25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:46<02:08,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03463   0.03048   0.01822   0.08333        41       640:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:46<02:07,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03447   0.02998   0.01787   0.08233        22       640:  27%|â–ˆâ–ˆâ–‹       | 17/64 [00:49<02:07,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03447   0.02998   0.01787   0.08233        22       640:  28%|â–ˆâ–ˆâ–Š       | 18/64 [00:49<02:05,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03393   0.03299   0.01816   0.08507        59       640:  28%|â–ˆâ–ˆâ–Š       | 18/64 [00:52<02:05,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03393   0.03299   0.01816   0.08507        59       640:  30%|â–ˆâ–ˆâ–‰       | 19/64 [00:52<02:03,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03423   0.03238    0.0193   0.08591        29       640:  30%|â–ˆâ–ˆâ–‰       | 19/64 [00:55<02:03,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03423   0.03238    0.0193   0.08591        29       640:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:55<02:00,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03397   0.03299   0.01878   0.08575        53       640:  31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:58<02:00,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03397   0.03299   0.01878   0.08575        53       640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/64 [00:58<01:59,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03353   0.03285   0.01827   0.08465        45       640:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/64 [01:00<01:59,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03353   0.03285   0.01827   0.08465        45       640:  34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [01:00<01:54,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03375   0.03301   0.01837   0.08513        48       640:  34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [01:03<01:54,  2.73s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03375   0.03301   0.01837   0.08513        48       640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [01:03<01:50,  2.70s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03355   0.03261   0.01776   0.08393        44       640:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [01:05<01:50,  2.70s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03355   0.03261   0.01776   0.08393        44       640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [01:05<01:47,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03419   0.03233   0.01768   0.08419        26       640:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [01:08<01:47,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03419   0.03233   0.01768   0.08419        26       640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [01:08<01:45,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0342    0.0324   0.01865   0.08525        27       640:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [01:11<01:45,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0342    0.0324   0.01865   0.08525        27       640:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [01:11<01:41,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03408   0.03301   0.01833   0.08543        42       640:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [01:13<01:41,  2.68s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03408   0.03301   0.01833   0.08543        42       640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [01:13<01:38,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03401   0.03331   0.01809   0.08541        71       640:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [01:16<01:38,  2.67s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03401   0.03331   0.01809   0.08541        71       640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [01:16<01:36,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03378   0.03282   0.01757   0.08417        12       640:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [01:19<01:36,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03378   0.03282   0.01757   0.08417        12       640:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [01:19<01:34,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03349    0.0324   0.01713   0.08302        30       640:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [01:22<01:34,  2.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03349    0.0324   0.01713   0.08302        30       640:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [01:22<01:31,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03335   0.03199    0.0168   0.08214        36       640:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [01:24<01:31,  2.69s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03335   0.03199    0.0168   0.08214        36       640:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [01:24<01:29,  2.70s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03312   0.03186   0.01635   0.08134        32       640:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [01:28<01:29,  2.70s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03312   0.03186   0.01635   0.08134        32       640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [01:28<01:34,  2.96s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03306   0.03137   0.01644   0.08086        40       640:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [01:31<01:34,  2.96s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03306   0.03137   0.01644   0.08086        40       640:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [01:31<01:29,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0331   0.03116   0.01658   0.08084         8       640:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [01:33<01:29,  2.90s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0331   0.03116   0.01658   0.08084         8       640:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [01:33<01:25,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03307   0.03082   0.01634   0.08022        13       640:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 34/64 [01:36<01:25,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03307   0.03082   0.01634   0.08022        13       640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [01:36<01:20,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03302   0.03054   0.01637   0.07993        22       640:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [01:39<01:20,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03302   0.03054   0.01637   0.07993        22       640:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [01:39<01:17,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03303   0.03067   0.01615   0.07985        62       640:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [01:41<01:17,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03303   0.03067   0.01615   0.07985        62       640:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [01:41<01:14,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03328   0.03044   0.01615   0.07986        27       640:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [01:44<01:14,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03328   0.03044   0.01615   0.07986        27       640:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [01:44<01:12,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03321   0.03007   0.01588   0.07916        15       640:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [01:47<01:12,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03321   0.03007   0.01588   0.07916        15       640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [01:47<01:09,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03301   0.03095   0.01571   0.07967        59       640:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [01:50<01:09,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03301   0.03095   0.01571   0.07967        59       640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/64 [01:50<01:08,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03285   0.03156   0.01543   0.07984        64       640:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/64 [01:53<01:08,  2.84s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03285   0.03156   0.01543   0.07984        64       640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [01:53<01:05,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0327   0.03127   0.01539   0.07936        15       640:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [01:56<01:05,  2.83s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0327   0.03127   0.01539   0.07936        15       640:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [01:56<01:02,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03266   0.03109   0.01548   0.07923        61       640:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [01:58<01:02,  2.82s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03266   0.03109   0.01548   0.07923        61       640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [01:58<00:59,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03253   0.03085   0.01536   0.07874        29       640:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [02:01<00:59,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03253   0.03085   0.01536   0.07874        29       640:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [02:01<00:56,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03268     0.031   0.01524   0.07891        27       640:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [02:04<00:56,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03268     0.031   0.01524   0.07891        27       640:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [02:04<00:52,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03239   0.03055   0.01492   0.07786         4       640:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [02:07<00:52,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03239   0.03055   0.01492   0.07786         4       640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [02:07<00:50,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03237   0.03023   0.01478   0.07738         6       640:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [02:10<00:50,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03237   0.03023   0.01478   0.07738         6       640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 47/64 [02:10<00:47,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03234   0.03016    0.0146    0.0771        73       640:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 47/64 [02:12<00:47,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03234   0.03016    0.0146    0.0771        73       640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/64 [02:12<00:44,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03233      0.03   0.01446   0.07679        47       640:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/64 [02:15<00:44,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03233      0.03   0.01446   0.07679        47       640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [02:15<00:41,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0322   0.03005   0.01434   0.07659        37       640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [02:18<00:41,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0322   0.03005   0.01434   0.07659        37       640:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [02:18<00:38,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03213   0.02987   0.01419    0.0762        35       640:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [02:21<00:38,  2.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03213   0.02987   0.01419    0.0762        35       640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [02:21<00:35,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03213   0.03022   0.01408   0.07643        71       640:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [02:23<00:35,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03213   0.03022   0.01408   0.07643        71       640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [02:23<00:33,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0321   0.02994   0.01392   0.07596        22       640:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [02:26<00:33,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G    0.0321   0.02994   0.01392   0.07596        22       640:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 53/64 [02:26<00:29,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03195   0.02988   0.01372   0.07555        36       640:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 53/64 [02:29<00:29,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03195   0.02988   0.01372   0.07555        36       640:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [02:29<00:27,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03178    0.0296   0.01367   0.07505         8       640:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [02:32<00:27,  2.72s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03178    0.0296   0.01367   0.07505         8       640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [02:32<00:24,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03175   0.02937   0.01352   0.07464        13       640:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [02:34<00:24,  2.74s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03175   0.02937   0.01352   0.07464        13       640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [02:34<00:22,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03159   0.02918   0.01346   0.07424        11       640:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [02:37<00:22,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03159   0.02918   0.01346   0.07424        11       640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [02:37<00:19,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03147   0.02906   0.01336   0.07389        23       640:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [02:40<00:19,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03147   0.02906   0.01336   0.07389        23       640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [02:40<00:16,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03162   0.02995   0.01362    0.0752        82       640:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [02:43<00:16,  2.81s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03162   0.02995   0.01362    0.0752        82       640:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [02:43<00:14,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03165   0.02964   0.01352   0.07481        20       640:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [02:46<00:14,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03165   0.02964   0.01352   0.07481        20       640:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [02:46<00:11,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03151   0.02968   0.01373   0.07492        21       640:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [02:48<00:11,  2.79s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03151   0.02968   0.01373   0.07492        21       640:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [02:48<00:08,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03148   0.02947   0.01364   0.07459        17       640:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [02:51<00:08,  2.80s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03148   0.02947   0.01364   0.07459        17       640:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [02:51<00:05,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03148   0.02922   0.01361   0.07432        11       640:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [02:54<00:05,  2.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03148   0.02922   0.01361   0.07432        11       640:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [02:54<00:02,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03163   0.02949   0.01373   0.07486        51       640:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [02:57<00:02,  2.76s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03163   0.02949   0.01373   0.07486        51       640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [02:57<00:00,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m 1/4        0G   0.03163   0.02949   0.01373   0.07486        51       640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [02:57<00:00,  2.77s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0%|          | 0/32 [00:00<?, ?it/s]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   3%|â–Ž         | 1/32 [00:01<00:35,  1.15s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   6%|â–‹         | 2/32 [00:02<00:41,  1.39s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   9%|â–‰         | 3/32 [00:04<00:42,  1.45s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  12%|â–ˆâ–Ž        | 4/32 [00:05<00:41,  1.49s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  16%|â–ˆâ–Œ        | 5/32 [00:07<00:40,  1.51s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  19%|â–ˆâ–‰        | 6/32 [00:08<00:39,  1.52s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  22%|â–ˆâ–ˆâ–       | 7/32 [00:10<00:38,  1.53s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:11<00:36,  1.53s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  28%|â–ˆâ–ˆâ–Š       | 9/32 [00:13<00:35,  1.54s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:15<00:36,  1.64s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:17<00:35,  1.71s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:19<00:34,  1.75s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:20<00:33,  1.78s/it]\n",
      "\u001b[36mnc0hdyraoc-algo-1-qdwti |\u001b[0m Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:22<00:32,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "git_config = {'repo': 'https://github.com/WongKinYiu/yolov7.git', 'branch': 'main'}\n",
    "\n",
    "hyperparameters = {'data': '/opt/ml/input/data/cfg/coco128.yaml', \n",
    "                   'cfg': '/opt/ml/code/cfg/training/yolov7.yaml', \n",
    "#                    'hyp': '/opt/ml/code/data/hyp.scratch.p5.yaml', \n",
    "                   'weight': '/opt/ml/input/data/weights/yolov7.pt',\n",
    "                   'project': '/opt/ml/model/',\n",
    "                   'name': 'tutorial', 'img': 640, 'batch': 2, 'epochs': 5, 'workers': 1}  # set batch and workers to 1, becasue of shared memory issue in local mode\n",
    "#                    'name': 'tutorial', 'img': 640, 'batch': 8, 'epochs': 5, 'workers': 1, 'device': '0,1,2,3,4,5,6,7'}  # set batch and workers to 1, becasue of shared memory issue in local mode\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='.',\n",
    "                            git_config=git_config,\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            framework_version='1.9.1',  # '1.8.1', '1.9.1'\n",
    "                            py_version='py38',  # 'py3', 'py38'\n",
    "                            script_mode=True,\n",
    "                            instance_count=1,  # 1 or 2 or ...\n",
    "                            instance_type=instance_type)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training using GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = '/home/ec2-user/SageMaker/yolov7_sagemaker/data/'\n",
    "data_location = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=prefix)\n",
    "# data_location = 's3://{}/{}'.format(bucket, prefix)\n",
    "inputs = {'cfg': data_location+'/cfg', 'weights': data_location+'/weights', 'images': data_location+'/images', 'labels': data_location+'/labels'}\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {'data': '/opt/ml/input/data/cfg/coco128.yaml', \n",
    "                   'cfg': '/opt/ml/code/cfg/training/yolov7.yaml', \n",
    "#                    'hyp': '/opt/ml/code/data/hyp.scratch.p5.yaml', \n",
    "                   'weight': '/opt/ml/input/data/weights/yolov7.pt',\n",
    "                   'project': '/opt/ml/model/',\n",
    "                   'name': 'tutorial', 'img': 640, 'batch': 16, 'epochs': 5}  # Single CPU or GPU\n",
    "#                    'name': 'tutorial', 'img': 640, 'batch': 16*8, 'epochs': 5, 'device': '0,1,2,3,4,5,6,7'}  # Multi-GPU: DP Mode\n",
    "\n",
    "instance_type = 'ml.p3.2xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "git_config = {'repo': 'https://github.com/WongKinYiu/yolov5.git', 'branch': 'main'}\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                            source_dir='.',\n",
    "                            git_config=git_config,\n",
    "                            role=role,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            framework_version='1.9.1',  # '1.8.1', '1.9.1'\n",
    "                            py_version='py38',  # 'py3', 'py38'\n",
    "                            script_mode=True,\n",
    "                            instance_count=1,  # 1 or 2 or ...\n",
    "                            instance_type=instance_type)\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "# training_job_name = 'pytorch-training-2022-03-03-04-38-25-840'\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint (in this case locally) which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model.tar.gz\n",
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz .\n",
    "!tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model-pytorch.tar.gz\n",
    "!cp tutorial/weights/best.pt model/\n",
    "!cd model && tar -czvf ../model-pytorch.tar.gz *\n",
    "\n",
    "!aws s3 cp model-pytorch.tar.gz s3://$bucket/$training_job_name/output/model-pytorch.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instance_type = 'local'\n",
    "instance_type = 'ml.m5.xlarge'\n",
    "\n",
    "# predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://{}/{}/output/model-pytorch.tar.gz'.format(bucket, training_job_name), role=role,\n",
    "                             entry_point='inference.py', framework_version='1.9.1', py_version='py38')  # TODO set model_server_workers=1 to avoid torchhub bug, model_server_workers=1\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('data/images/inference/bus.jpg')\n",
    "\n",
    "# print('image:', type(image), image.shape, image.dtype)\n",
    "outputs = predictor.predict(image)\n",
    "print('outputs: ', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model to SageMaker Endpoint Serverless (Preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model-pytorch.tar.gz s3://$bucket/$training_job_name/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=1,\n",
    ")\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=sagemaker_session.boto_region_name,\n",
    "    version=\"1.9.1\",  # \"1.8.1\", \"1.9.1\"\n",
    "    py_version=\"py38\",  # \"py3\", \"py38\"\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "print(image_uri)\n",
    "\n",
    "estimator = PyTorch.attach(training_job_name=training_job_name)\n",
    "serverless_predictor = estimator.deploy(serverless_inference_config=serverless_config, image_uri=image_uri, entry_point='inference.py')  # , model_server_workers=1\n",
    "\n",
    "# pytorch_model = PyTorchModel(model_data='s3://{}/{}/output/model-pytorch.tar.gz'.format(bucket, training_job_name), role=role,\n",
    "#                              entry_point='inference.py', framework_version='1.9.1', py_version='py38')  # TODO set model_server_workers=1 to avoid torchhub bug, model_server_workers=1\n",
    "# serverless_predictor = pytorch_model.deploy(serverless_inference_config=serverless_config, image_uri=image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('data/images/inference/bus.jpg')\n",
    "\n",
    "# print('image:', type(image), image.shape, image.dtype)\n",
    "outputs = serverless_predictor.predict(image)\n",
    "print('outputs: ', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverless_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
